{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression\n",
    "\n",
    "## Unterschied Regression <-> Klassifikation/Klassifizierung\n",
    "\n",
    "> 2 Kategorien in \"Supervised Learning\"\n",
    "\n",
    "### Regression:\n",
    "\n",
    "> Vorhersagen bei denen Label(*Zielvariable*) **kontinuierlich** ist: $y \\in \\mathbb{R}$\n",
    "\n",
    "* Lineare Regression\n",
    "* Regressionsbäume\n",
    "\n",
    "$\\Rightarrow$ Vorhersage Umsatz, Temperatur, Größe, ...\n",
    "\n",
    "### Klassifikation/Klassifizierung\n",
    "\n",
    "> Vorhersagen, bei denen Label **kategorisch** ist: $y \\in {0,...,k}$\n",
    "\n",
    "* Logitische Regression\n",
    "* Entscheidungsbäume\n",
    "* Ensemble-Bäume\n",
    "* Neuronale Netze/Deep Learning\n",
    "\n",
    "$\\Rightarrow$ Bestimmte Farben, Bestimmte Kategorien an Tieren, ...\n",
    "\n",
    "1. **Binäre Klassifizierung**: Genau 2 Labels(X oder Y $\\rightarrow$ 0 oder 1)\n",
    "2. **Mehrklassen Klassifiezierung**: Mehr als 2 Kategorien(A, B oder C $\\rightarrow$ 0, 1 oder k)\n",
    "\n",
    "## Logistische Funktion\n",
    "\n",
    "> Funktion die auf den Wertebereich $[0,1]$ abbildet\n",
    "\n",
    "$f(x)= \\frac{1}{1+e^{-x}}; f: \\mathbb{R} \\rightarrow [0,1]$\n",
    "\n",
    "* Anstelle von Geraden, bei logistischer Regression logistische Funktion als Vorhersagefunktion genutzt:\n",
    "\n",
    "1. Ein Feature: $f(x)= \\frac{1}{1+e^-{w_0+w_1x}}$\n",
    "2. Mehrere Features: $f(x)= \\frac{1}{1+e^{-(w_0+w_1x + w_2x_2 + .... + w_nx_n}}$\n",
    "\n",
    "Dabei jeweils:\n",
    "\n",
    "1. $w_n$: Parameter des Modells, die gerlent werden müssen($\\Rightarrow$ *Gradient Descent*)\n",
    "2. $x_n$: Features des Datenpunkts(Tiername, Preis,...)\n",
    "\n",
    "### Vorhersage durch logistische Regression\n",
    "\n",
    "Muster dabei:\n",
    "\n",
    "Gegeben | Gesucht\n",
    "--- | ---\n",
    "Feature $x_1$: 44 | Label abc $y=0$\n",
    "Feature $x_2$: 179| Label qwe $y=1$\n",
    "... | ....\n",
    "Feature $x_n$: ... | Label xyz ...\n",
    "\n",
    "Gewichten aus bereits trainierten Models: $w_0 = -30; w_1 = 0.2; w_2 = 0.13$\n",
    "\n",
    "$\\Rightarrow f(x) = \\frac{1}{1+e^{-(30+0.2*44+0.13*179)}} = 0.887$\n",
    "\n",
    "$\\rightarrow$ x mit der Wahrscheinlichkeit 0.887 dem Label *qwe* zuzuordnen.\n",
    "\n",
    "Fachwörter:\n",
    "\n",
    "* *Klassenzugehörigkeit*: Zu welcher konkreten Klasse als Output gehört die Vorhersage an\n",
    "* *Decision boundary*: Grenze für die Zuordnung zu einer bestimmten Klasse\n",
    "\n",
    "### Modelltraining bei der logistischen Regression\n",
    "\n",
    "Wie bei linearen Regression:\n",
    "\n",
    "1. **Kostenfunkton $J(w)$** definieren, welche den Vorhersagefehler auf Trainingsdaten in Abhängigkeit der Modellparameter $w$ angibt\n",
    "2. Kostenfunktion mit hilfe von **Gradient Descent** minimieren, um Minimum der Funktion finden(Optimalen Parametern $\\hat{w}$)\n",
    "\n",
    "#### Kostenfunktion\n",
    "\n",
    "> Beschreibt Vorhersagefehler auf $n$ Trainingsdaten in Abhängigkeit von $w$\n",
    "\n",
    "1. Lineare Regression: MSE(See Chapter 2)\n",
    "2. Logistische Regression:\n",
    "* Cross Entropy: $J(w) = - \\sum_{i=1}^n y_ilog(f(x_i)) + (1-y_i)log(1-f(x_i))$\n",
    "* Cross Entropy bestraft Klassifikation härter\n",
    "* Kostenfunktion konvex $\\rightarrow$ Minimum durch Gardient Descent bstimmt werden. Mit Log. Reg. & MSE nicht möglich.\n",
    "\n",
    "<!-- TODO Gradient descent speicalliy -->\n",
    "\n",
    "#### Evaluierung\n",
    "\n",
    "* Nicht wie lineare Regression über Kostenfunkton, sondern über Klassenzugehörigkeit\n",
    "\n",
    "Evaluierungsmetriken:\n",
    "\n",
    "1. Accuracy\n",
    "2. Precision & Recall\n",
    "3. F1-Score\n",
    "\n",
    "##### Entscheidungsfälle\n",
    "\n",
    "Abhängig von durch Modell vorhergesagten Klassen & Label des Datenpunkts:\n",
    "\n",
    "Fall | Vorhersage | Label | Bezeichnung\n",
    "--- | --- | --- | --- \n",
    "1 | 1 | 1 | True Positive  \n",
    "2 | 1 | 0 | False Positive\n",
    "3 | 0 | 1 | False Negative\n",
    "4 | 0 | 0 | True Negative\n",
    "\n",
    "* Bei Eval., für jeden Datenpunkt in Testdaten bestmmt, welcher Entscheidungsfall eintritt. Nach Muster:\n",
    "\n",
    "Vorhersage | Label | Fall\n",
    "--- | --- | ---\n",
    "... | ... | tp/fp/fn/tn\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "> Vorhersagen möglichst **genau** sein\n",
    "\n",
    "* Gute Vorhersagen: tp || tn\n",
    "* Schlechte Vorhersagen: fp || fn\n",
    "\n",
    "$accuracy = \\frac{true \\: positives \\: + \\: true \\: negatives}{all}$\n",
    "\n",
    "$\\Rightarrow$ Wie viel Prozent d. Vorhersagen sind korrekt?\n",
    "\n",
    "#### Precision\n",
    "\n",
    "> Vorhersagen möglichst **präzise** sein\n",
    "\n",
    "$precision = \\frac{true \\: positives}{true positives \\: + \\: false \\: positives}$\n",
    "\n",
    "$\\Rightarrow$ Wie viel Prozent d. Vorhersagen positiven Fälle(\"1\") sind auch wirklich positiv?\n",
    "\n",
    "#### Recall\n",
    "\n",
    "> Vorhersagen möglichst **hohe Trefferquote** haben\n",
    "\n",
    "$recall = \\frac{true \\: positives}{true positives \\: + \\: false \\: negatives}$\n",
    "\n",
    "$\\Rightarrow$ Wie viel Prozent d. Vorhersagen positiven Fälle(\"1\") erkennt das Modell?\n",
    "\n",
    "#### Unterschied Precision & Recall\n",
    "\n",
    "<img  style=\"display: block; margin: auto;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png\" width=\"400\" height=\"400\" />\n",
    "\n",
    "Quelle: https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "#### F1 Score\n",
    "\n",
    "> Vorhersagen möglichst **hohe Trefferquote** haben als auch **präzise** sein\n",
    "\n",
    "$F_1 = 2* \\frac{precision \\: * \\: recall}{precision \\: + \\: recall}$\n",
    "\n",
    "## Multinominale Logistische Regression\n",
    "\n",
    "> Klassifikation bei mehr als 2 Klassen: Lerne $k$ logistische Regressionsmodelle\n",
    "\n",
    "* Vorhersage für Datenpunkt $\\hat{=}$ Klasse für welche das zugehörige Modell die höchste Vorhersagewahrscheinlichkeit ausgibt.\n",
    "\n",
    "$x` \\Rightarrow max(f_i(x`))$\n",
    "\n",
    "* Precision & Recall können nicht bestimmt werden\n",
    "* Accuracy schon: $accuracy = \\frac{korrekte \\: Vorhersagen}{alle \\: Vorhersagen}$\n",
    "* Auch **Confusion Matrix genutzt**:\n",
    "\n",
    ". | Vorhersage 1 | Vorhersage 2 | Vorhersage 3\n",
    "--- | --- | --- | ---\n",
    "Label 1 | Wahrsch. X | Wahrsch. Y | Wahrsch. Z\n",
    "Label 2 | Wahrsch. A | Wahrsch. B | Wahrsch. C\n",
    "Label 3 | Wahrsch. Q | Wahrsch. W | Wahrsch. E\n",
    "\n",
    "* Diagonale Einträge $\\hat{=}$ Anteil der Korrekten Vorhersagen für jeweilige Klasse\n",
    "* Siehe: https://en.wikipedia.org/wiki/Confusion_matrix für Beispiele\n",
    "\n",
    "## Feature importance\n",
    "\n",
    "> Wie wichtig jeweilige Feature für Vorhersage ist\n",
    "\n",
    "* Bei linearer & logistischer Reression, Feature importance direkt an Gewichten der Features abgelesen werden:\n",
    "\n",
    "1. $Hohes \\: Gewicht \\Rightarrow Hohe \\: Feature \\: Importance$\n",
    "2. $Niedriges \\: Gewicht \\Rightarrow Niedrige \\: Feature \\: Importance$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
