{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression\n",
    "\n",
    "## Unterschied Regression <-> Klassifikation/Klassifizierung\n",
    "\n",
    "> 2 Kategorien in \"Supervised Learning\"\n",
    "\n",
    "### Regression:\n",
    "\n",
    "> Vorhersagen bei denen Label(*Zielvariable*) **kontinuierlich** ist: $y \\in \\mathbb{R}$\n",
    "\n",
    "* Lineare Regression\n",
    "* Regressionsbäume\n",
    "\n",
    "$\\Rightarrow$ Vorhersage Umsatz, Temperatur, Größe, ...\n",
    "\n",
    "### Klassifikation/Klassifizierung\n",
    "\n",
    "> Vorhersagen, bei denen Label **kategorisch** ist: $y \\in {0,...,k}$\n",
    "\n",
    "* Logitische Regression\n",
    "* Entscheidungsbäume\n",
    "* Ensemble-Bäume\n",
    "* Neuronale Netze/Deep Learning\n",
    "\n",
    "$\\Rightarrow$ Bestimmte Farben, Bestimmte Kategorien an Tieren, ...\n",
    "\n",
    "1. **Binäre Klassifizierung**: Genau 2 Labels(X oder Y $\\rightarrow$ 0 oder 1)\n",
    "2. **Mehrklassen Klassifiezierung**: Mehr als 2 Kategorien(A, B oder C $\\rightarrow$ 0, 1 oder k)\n",
    "\n",
    "## Logistische Funktion\n",
    "\n",
    "> Funktion die auf den Wertebereich $[0,1]$ abbildet\n",
    "\n",
    "$f(x)= \\frac{1}{1+e^{-x}}; f: \\mathbb{R} \\rightarrow [0,1]$\n",
    "\n",
    "* Anstelle von Geraden, bei logistischer Regression logistische Funktion als Vorhersagefunktion genutzt:\n",
    "\n",
    "1. Ein Feature: $f(x)= \\frac{1}{1+e^-{w_0+w_1x}}$\n",
    "2. Mehrere Features: $f(x)= \\frac{1}{1+e^{-(w_0+w_1x + w_2x_2 + .... + w_nx_n}}$\n",
    "\n",
    "Dabei jeweils:\n",
    "\n",
    "1. $w_n$: Parameter des Modells, die gerlent werden müssen($\\Rightarrow$ *Gradient Descent*)\n",
    "2. $x_n$: Features des Datenpunkts(Tiername, Preis,...)\n",
    "\n",
    "### Vorhersage durch logistische Regression\n",
    "\n",
    "Muster dabei:\n",
    "\n",
    "Gegeben | Gesucht\n",
    "--- | ---\n",
    "Feature $x_1$: 44 | Label abc $y=0$\n",
    "Feature $x_2$: 179| Label qwe $y=1$\n",
    "... | ....\n",
    "Feature $x_n$: ... | Label xyz ...\n",
    "\n",
    "Gewichten aus bereits trainierten Models: $w_0 = -30; w_1 = 0.2; w_2 = 0.13$\n",
    "\n",
    "$\\Rightarrow f(x) = \\frac{1}{1+e^{-(30+0.2*44+0.13*179)}} = 0.887$\n",
    "\n",
    "$\\rightarrow$ x mit der Wahrscheinlichkeit 0.887 dem Label *qwe* zuzuordnen.\n",
    "\n",
    "Fachwörter:\n",
    "\n",
    "* *Klassenzugehörigkeit*: Zu welcher konkreten Klasse als Output gehört die Vorhersage an\n",
    "* *Decision boundary*: Grenze für die Zuordnung zu einer bestimmten Klasse\n",
    "\n",
    "### Modelltraining bei der logistischen Regression\n",
    "\n",
    "Wie bei linearen Regression:\n",
    "\n",
    "1. **Kostenfunkton $J(w)$** definieren, welche den Vorhersagefehler auf Trainingsdaten in Abhängigkeit der Modellparameter $w$ angibt\n",
    "2. Kostenfunktion mit hilfe von **Gradient Descent** minimieren, um Minimum der Funktion finden(Optimalen Parametern $\\hat{w}$)\n",
    "\n",
    "#### Kostenfunktion\n",
    "\n",
    "> Beschreibt Vorhersagefehler auf $n$ Trainingsdaten in Abhängigkeit von $w$\n",
    "\n",
    "1. Lineare Regression: MSE(See Chapter 2)\n",
    "2. Logistische Regression:\n",
    "* Cross Entropy: $J(w) = - \\sum_{i=1}^n y_ilog(f(x_i)) + (1-y_i)log(1-f(x_i))$\n",
    "* Cross Entropy bestraft Klassifikation härter\n",
    "* Kostenfunktion konvex $\\rightarrow$ Minimum durch Gardient Descent bstimmt werden. Mit Log. Reg. & MSE nicht möglich.\n",
    "\n",
    "<!-- TODO Gradient descent speicalliy -->\n",
    "\n",
    "#### Evaluierung\n",
    "\n",
    "* Nicht wie lineare Regression über Kostenfunkton, sondern über Klassenzugehörigkeit\n",
    "\n",
    "Evaluierungsmetriken:\n",
    "\n",
    "1. Accuracy\n",
    "2. Precision & Recall\n",
    "3. F1-Score\n",
    "\n",
    "##### Entscheidungsfälle\n",
    "\n",
    "Abhängig von durch Modell vorhergesagten Klassen & Label des Datenpunkts:\n",
    "\n",
    "Fall | Vorhersage | Label | Bezeichnung\n",
    "--- | --- | --- | --- \n",
    "1 | 1 | 1 | True Positive  \n",
    "2 | 1 | 0 | False Positive\n",
    "3 | 0 | 1 | False Negative\n",
    "4 | 0 | 0 | True Negative\n",
    "\n",
    "* Bei Eval., für jeden Datenpunkt in Testdaten bestmmt, welcher Entscheidungsfall eintritt. Nach Muster:\n",
    "\n",
    "Vorhersage | Label | Fall\n",
    "--- | --- | ---\n",
    "... | ... | tp/fp/fn/tn\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "> Vorhersagen möglichst **genau** sein\n",
    "\n",
    "* Gute Vorhersagen: tp || tn\n",
    "* Schlechte Vorhersagen: fp || fn\n",
    "\n",
    "$accuracy = \\frac{true \\: positives \\: + \\: true \\: negatives}{all}$\n",
    "\n",
    "$\\Rightarrow$ Wie viel Prozent d. Vorhersagen sind korrekt?\n",
    "\n",
    "#### Precision\n",
    "\n",
    "> Vorhersagen möglichst **präzise** sein\n",
    "\n",
    "$precision = \\frac{true \\: positives}{true positives \\: + \\: false \\: positives}$\n",
    "\n",
    "$\\Rightarrow$ Wie viel Prozent d. Vorhersagen positiven Fälle(\"1\") sind auch wirklich positiv?\n",
    "\n",
    "#### Recall\n",
    "\n",
    "> Vorhersagen möglichst **hohe Trefferquote** haben\n",
    "\n",
    "$recall = \\frac{true \\: positives}{true positives \\: + \\: false \\: negatives}$\n",
    "\n",
    "$\\Rightarrow$ Wie viel Prozent d. Vorhersagen positiven Fälle(\"1\") erkennt das Modell?\n",
    "\n",
    "#### Unterschied Precision & Recall\n",
    "\n",
    "<img  style=\"display: block; margin: auto;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png\" width=\"400\" height=\"400\" />\n",
    "\n",
    "Quelle: https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "#### F1 Score\n",
    "\n",
    "> Vorhersagen möglichst **hohe Trefferquote** haben als auch **präzise** sein\n",
    "\n",
    "$F_1 = 2* \\frac{precision \\: * \\: recall}{precision \\: + \\: recall}$\n",
    "\n",
    "## Multinominale Logistische Regression\n",
    "\n",
    "> Klassifikation bei mehr als 2 Klassen: Lerne $k$ logistische Regressionsmodelle\n",
    "\n",
    "* Vorhersage für Datenpunkt $\\hat{=}$ Klasse für welche das zugehörige Modell die höchste Vorhersagewahrscheinlichkeit ausgibt.\n",
    "\n",
    "$x` \\Rightarrow max(f_i(x`))$\n",
    "\n",
    "* Precision & Recall können nicht bestimmt werden\n",
    "* Accuracy schon: $accuracy = \\frac{korrekte \\: Vorhersagen}{alle \\: Vorhersagen}$\n",
    "* Auch **Confusion Matrix genutzt**:\n",
    "\n",
    ". | Vorhersage 1 | Vorhersage 2 | Vorhersage 3\n",
    "--- | --- | --- | ---\n",
    "Label 1 | Wahrsch. X | Wahrsch. Y | Wahrsch. Z\n",
    "Label 2 | Wahrsch. A | Wahrsch. B | Wahrsch. C\n",
    "Label 3 | Wahrsch. Q | Wahrsch. W | Wahrsch. E\n",
    "\n",
    "* Diagonale Einträge $\\hat{=}$ Anteil der Korrekten Vorhersagen für jeweilige Klasse\n",
    "* Siehe: https://en.wikipedia.org/wiki/Confusion_matrix für Beispiele\n",
    "\n",
    "## Feature importance\n",
    "\n",
    "> Wie wichtig jeweilige Feature für Vorhersage ist\n",
    "\n",
    "* Bei linearer & logistischer Reression, Feature importance direkt an Gewichten der Features abgelesen werden:\n",
    "\n",
    "1. $Hohes \\: Gewicht \\Rightarrow Hohe \\: Feature \\: Importance$\n",
    "2. $Niedriges \\: Gewicht \\Rightarrow Niedrige \\: Feature \\: Importance$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>winpercent</th>\n",
       "      <th>chocolate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>66.971725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.511</td>\n",
       "      <td>67.602936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.116</td>\n",
       "      <td>32.261086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.511</td>\n",
       "      <td>46.116505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.511</td>\n",
       "      <td>52.341465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fruity  caramel  peanutyalmondy  nougat  crispedricewafer  hard  bar  \\\n",
       "0       0        1               0       0                 1     0    1   \n",
       "1       0        0               0       1                 0     0    1   \n",
       "2       0        0               0       0                 0     0    0   \n",
       "3       0        0               0       0                 0     0    0   \n",
       "4       1        0               0       0                 0     0    0   \n",
       "\n",
       "   pluribus  sugarpercent  pricepercent  winpercent  chocolate  \n",
       "0         0         0.732         0.860   66.971725          1  \n",
       "1         0         0.604         0.511   67.602936          1  \n",
       "2         0         0.011         0.116   32.261086          0  \n",
       "3         0         0.011         0.511   46.116505          0  \n",
       "4         0         0.906         0.511   52.341465          0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load data set and check it out\n",
    "\n",
    "# Using the candy dataset: https://www.kaggle.com/fivethirtyeight/the-ultimate-halloween-candy-power-ranking/\n",
    "# Question to make prediction on: Is given candy chocolate?\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./datasets/candy-data.csv')\n",
    "\n",
    "# Remove not needed name\n",
    "df = df[['fruity','caramel','peanutyalmondy','nougat','crispedricewafer','hard', 'bar','pluribus','sugarpercent','pricepercent','winpercent','chocolate']] \t\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training data size: 68\n",
      "Our test data size: 17\n"
     ]
    }
   ],
   "source": [
    "# 2. Split into test and training data\n",
    "\n",
    "# In comparison to 1) we'll now use sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainingSet, testSet = train_test_split(df, test_size=0.2, random_state=0) # 80/20 Split\n",
    "# Manually create splits, as we want to predict chocolate\n",
    "X_train = trainingSet[['fruity','caramel','peanutyalmondy','nougat','crispedricewafer','hard', 'bar','pluribus','sugarpercent','pricepercent','winpercent']] \t\n",
    "y_train = trainingSet[\"chocolate\"]\n",
    "\n",
    "X_test = testSet[['fruity','caramel','peanutyalmondy','nougat','crispedricewafer','hard', 'bar','pluribus','sugarpercent','pricepercent','winpercent']] \t\n",
    "y_test = testSet[\"chocolate\"]\n",
    "\n",
    "print(f'Our training data size: {str(len(X_train))}')\n",
    "print(f'Our test data size: {str(len(y_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Train model using logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegr = LogisticRegression(max_iter=1000) # Gradient Descent with max. 1000 Steps\n",
    "logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create prediction\n",
    "y_prediction = logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.0%\n",
      "Precision: 100.0%\n",
      "Recall: 0.75\n"
     ]
    }
   ],
   "source": [
    "# 5. Calculate accuracy, precision and recall with prediction\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "test_accuracy = accuracy_score(y_test, y_prediction)\n",
    "test_precision = precision_score(y_test, y_prediction)\n",
    "test_recall = recall_score(y_test, y_prediction)\n",
    "\n",
    "print(f'Accuracy: {round(test_accuracy*100)}%\\nPrecision: {round(test_precision*100)}%\\nRecall: {test_recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.94        17\n",
      "   macro avg       0.96      0.88      0.91        17\n",
      "weighted avg       0.95      0.94      0.94        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Run confussion matrix to determnine accuracy of classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_prediction)\n",
    "print(classification_report(y_test, y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
